{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"avalanchepy","text":"<p>Python implementation of the avalanche sampling algorithm proposed in:</p> <p>Herzog, M. P., von Campe, H., Kuntz, R. M., R\u00f6ver, L., &amp; Sch\u00e4fer, B. M. (2023). Partition function approach to non-Gaussian likelihoods: macrocanonical partitions and replicating Markov-chains. arXiv preprint arXiv:2311.16218.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>A simple example might look like this:</p> <pre><code>import numpy as np\nimport avalanchepy\n\n# Define a simple gaussian likelihood function\ndef loglike(theta):\n    return -0.5 * np.sum(theta**2)\n\n# Run avalanchepy\nresult = avalanchepy.run(loglike, mu=3, n_total_steps=30000)\nresult.print_summary()\n</code></pre>"},{"location":"modules/","title":"Overview of the architecture","text":"<p>The most fundamental part of the sampler is given in <code>sampler.py</code> where the main Markov loop is:</p> <pre><code>for i in range(n_steps):\n    state = updater(state)\n    obervables[i] = [collector.collect(state) for collector in collectors]\n</code></pre> <p>From an abstract point of view, in each step, the state of the the system is updated by an <code>updater</code>, then all possible ovservables are measured by a list of <code>collectors</code>.</p> <p>To keep the code modular, one may combine different updaters and collectors. In particular, alternating between updates of the positions and 'kill/spawn' steps is handled by this. Similairly, there are collectors for multiple observables available, alternatively, one may define ones own.</p> <p>All of this is wrapped by the <code>run</code> function in <code>interface.py</code> that returns a <code>Result</code> object.</p>"},{"location":"modules/#the-sampler-itself-and-the-interface","title":"The sampler itself and the Interface","text":""},{"location":"modules/#avalanchepy.sampler.macro_sampler","title":"<code>macro_sampler(updater, n_total_steps, initial_positions, collectors, progress_bar=True, info_window_size=500)</code>","text":"<p>Runs the sampling at the lowest level of abstraction.</p> <p>Parameters:</p> Name Type Description Default <code>updater</code> <code>MCMCUpdater</code> <p>updates the state of the sampler in each step.</p> required <code>n_total_steps</code> <code>int</code> <p>includes move and kill/spawn steps.</p> required <code>initial_positions</code> <code>ndarray</code> <p>of the different chains.</p> required <code>collectors</code> <code>list[Collector]</code> <p>used to measure observables between steps.</p> required <code>progress_bar</code> <code>bool</code> <p>(using tqdm)</p> <code>True</code> <code>info_window_size</code> <code>int</code> <p>for the progress bar.</p> <code>500</code> <p>Returns:</p> Name Type Description <code>results</code> <code>dict</code> <p>contains the collected values for the observables and acceptance rates.</p> Source code in <code>avalanchepy/sampler.py</code> <pre><code>def macro_sampler(\n    updater: MCMCUpdater,\n    n_total_steps: int,\n    initial_positions: np.ndarray,  # of the chains\n    collectors: list[Collector],  # list of collectors\n    progress_bar: bool = True,  # whether to show a progress bar\n    info_window_size: int = 500,  # how many steps should be considered for the progress bar\n) -&gt; dict:\n    \"\"\"Runs the sampling at the lowest level of abstraction.\n\n    Args:\n        updater (MCMCUpdater): updates the state of the sampler in each step.\n        n_total_steps (int): includes move and kill/spawn steps.\n        initial_positions (np.ndarray): of the different chains.\n        collectors (list[Collector]): used to measure observables between steps.\n        progress_bar (bool): (using tqdm)\n        info_window_size (int): for the progress bar.\n\n    Returns:\n        results (dict): contains the collected values for the observables and acceptance rates.\n    \"\"\"\n\n    pos = initial_positions  # shape: (#chains, #dimensions)\n\n    rates = {\"move\": [0, 0], \"kill\": [0, 0], \"spawn\": [0, 0]}\n\n    t = trange(n_total_steps, desc=\"init\", leave=True) if progress_bar else range(n_total_steps)\n\n    for i in t:\n        if progress_bar and i &gt; info_window_size and i % info_window_size == 0:\n            info_str = \"\"\n            for collector in collectors:\n                info_str += f\"{collector.abbreviation} = {collector.get_recent_average(i, info_window_size):.2f}; \"\n            t.set_description(info_str[:-2], refresh=True)  # type: ignore[attr-defined]\n\n        # abort if there are no chains left\n        if pos.shape[0] &lt;= 2:\n            raise StopIteration(f\"No chains left after {i} iterations. Stopping.\")\n\n        # update step(s)\n        pos, touched_chain, action, success = updater(pos)\n\n        # store observable measurements\n        for collector in collectors:\n            collector.collect(pos, i, touched_chain, action, success)\n\n        # update rates\n        rates[action][0] += 1\n        rates[action][1] += success\n\n    # make results available\n    results = {\"rates\": rates}\n\n    for collector in collectors:\n        results[collector.name] = collector.get(i)\n        with contextlib.suppress(AttributeError):\n            results[collector.name + \"_clean\"] = collector.get_clean(i)\n        # if collector.hasattr(\"get_clean\"):\n        #     results[collector.name+\"_clean\"] = collector.get_clean(i)\n\n    return results\n</code></pre>"},{"location":"modules/#avalanchepy.interface.Result","title":"<code>Result</code>","text":"<p>             Bases: <code>dict</code></p> <p>Object containing the results of a run of the sampler. It's a dictionary with some additional methods for printing summaries and accessing the results more conveniently.</p> Source code in <code>avalanchepy/interface.py</code> <pre><code>class Result(dict):\n    \"\"\"Object containing the results of a run of the sampler.\n    It's a dictionary with some additional methods for printing summaries and accessing the results more conveniently.\n    \"\"\"\n\n    __getattr__ = dict.__getitem__\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\n    def __init__(self, values) -&gt; None:\n        super().__init__()\n        self.__dict__ = self\n\n        for key, value in values.items():\n            self[key] = value\n\n        self.n_chains_avg = self.n_chains_clean.mean()\n        self.log_evidence = np.log(self.n_chains_avg) - self.mu\n        self.log_evidence_err = self.n_chains_clean.std() / np.sqrt(len(self.n_chains_clean))\n\n    def print_summary(self) -&gt; None:\n        \"\"\"Prints a summary of the runs results.\"\"\"\n        print(self.summary())\n\n    def summary(self) -&gt; str:\n        \"\"\"Returns a summary of the runs results.\n\n        Returns:\n            str: Summary of results\n        \"\"\"\n        summary_str = \"\"\n        summary_str += \"mode: \" + str(self.mode) + \"\\n\"\n        summary_str += \"n_dim: \" + str(self.n_dim) + \"\\n\"\n        summary_str += \"n_samples: \" + str(len(self.samples_clean)) + \"\\n\"\n        summary_str += \"&lt;N&gt;: \" + str(self.n_chains_avg) + \"\\n\"\n        summary_str += \"Var(N): \" + str(self.n_chains.std()) + \"\\n\"\n        summary_str += \"log_evidence: \" + str(self.log_evidence) + \"\\n\"\n        summary_str += \"log_evidence_err: \" + str(self.log_evidence_err) + \"\\n\"\n        summary_str += \"evidence: \" + str(np.exp(self.log_evidence)) + \"\\n\"\n        summary_str += \"evidence_err: \" + str(np.exp(self.log_evidence) * self.log_evidence_err) + \"\\n\"\n\n        return summary_str\n</code></pre>"},{"location":"modules/#avalanchepy.interface.Result.print_summary","title":"<code>print_summary()</code>","text":"<p>Prints a summary of the runs results.</p> Source code in <code>avalanchepy/interface.py</code> <pre><code>def print_summary(self) -&gt; None:\n    \"\"\"Prints a summary of the runs results.\"\"\"\n    print(self.summary())\n</code></pre>"},{"location":"modules/#avalanchepy.interface.Result.summary","title":"<code>summary()</code>","text":"<p>Returns a summary of the runs results.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Summary of results</p> Source code in <code>avalanchepy/interface.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Returns a summary of the runs results.\n\n    Returns:\n        str: Summary of results\n    \"\"\"\n    summary_str = \"\"\n    summary_str += \"mode: \" + str(self.mode) + \"\\n\"\n    summary_str += \"n_dim: \" + str(self.n_dim) + \"\\n\"\n    summary_str += \"n_samples: \" + str(len(self.samples_clean)) + \"\\n\"\n    summary_str += \"&lt;N&gt;: \" + str(self.n_chains_avg) + \"\\n\"\n    summary_str += \"Var(N): \" + str(self.n_chains.std()) + \"\\n\"\n    summary_str += \"log_evidence: \" + str(self.log_evidence) + \"\\n\"\n    summary_str += \"log_evidence_err: \" + str(self.log_evidence_err) + \"\\n\"\n    summary_str += \"evidence: \" + str(np.exp(self.log_evidence)) + \"\\n\"\n    summary_str += \"evidence_err: \" + str(np.exp(self.log_evidence) * self.log_evidence_err) + \"\\n\"\n\n    return summary_str\n</code></pre>"},{"location":"modules/#avalanchepy.interface.run","title":"<code>run(log_probability, **kwargs)</code>","text":"<p>Performs a run of Avalanche Sampling. The idea is that only the log_probability potential needs to be passed as well as a 'mode' in which the sampler operates.</p> Modes <ul> <li> <p><code>\"static_spawn\"</code> : Positions for new chains are sampled from a static uniform distribution.     Keyword arguments:</p> Name Type Description Default <code>spawn_range</code> <code>tuple</code> Range from which to sample new chains. <code>(-3, 3)</code> </li> <li> <p><code>\"gaussian_static_spawn\"</code> : Positions for new chains are sampled from a static Gaussian distribution.     Keyword arguments:</p> Name Type Description Default <code>cov_spawn</code> <code>np.ndarray</code> Covariance matrix for the proposal distribution when spawning new chains. <code>np.eye(n_dim)</code> <code>mean</code> <code>np.ndarray</code> Mean of the proposal distribution when spawning new chains. <code>np.zeros(n_dim)</code> </li> <li> <p><code>\"proximity_spawn\"</code> : Positions for new chains are close to existing chains, chains are more likely to be killed when close to others.     Keyword arguments:</p> Name Type Description Default <code>cov_proximity</code> <code>np.ndarray</code> Covariance matrix for the proposal distribution when spawning new chains. <code>np.eye(n_dim)</code> </li> </ul> <p>Alternatively, keyword arguments allow to pass other arguments to the function, possibly overwriting those set by the mode.</p> <p>Parameters:</p> Name Type Description Default <code>log_probability</code> <code>function</code> <p>The logarithm of the probability function to be used. Also known as the chi^2 potential.</p> required <code>**kwargs</code> <p>Additional keyword arguments that can be passed to the function.</p> <code>{}</code> <p>optional keyword arguments:</p> Name Type Description Default <code>mode</code> <code>str</code> See above. <code>\"proximity_spawn\"</code> <code>mu</code> <code>float</code> Chemical potential. <code>3</code> <code>n_dim</code> <code>int</code> Number of dimensions. <code>2</code> <code>n_initial_particles</code> <code>int</code> Number of chains to start with. <code>100</code> <code>n_total_steps</code> <code>int</code> Number of total steps to take. <code>10000</code> <code>n_thinning</code> <code>int</code> Number of steps to skip before storing a sample. <code>10</code> <code>n_burn_in_steps</code> <code>int</code> Number of steps to skip before starting to store samples. <code>n_total_steps/3</code> <code>n_pos_updates_per_kill_spawn</code> <code>int</code> Number of position updates to perform before trying to spawn or kill a chain. <code>5</code> <code>cov_move</code> <code>np.ndarray</code> Covariance matrix for the proposal distribution when moving particles. <code>np.eye(n_dim)</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Result</code> <p>The result of the Avalanche Sampling run.</p> Source code in <code>avalanchepy/interface.py</code> <pre><code>def run(log_probability: Callable, **kwargs) -&gt; Result:\n    \"\"\"\n    Performs a run of Avalanche Sampling. The idea is that only the log_probability potential needs to be passed\n    as well as a 'mode' in which the sampler operates.\n\n    Modes:\n        - `\"static_spawn\"` : Positions for new chains are sampled from a static uniform distribution.\n            Keyword arguments:\n\n            | Name         | Type         | Description                                     | Default     |\n            |--------------|--------------|-------------------------------------------------|-------------|\n            | `spawn_range`| `tuple`      | Range from which to sample new chains.          | `(-3, 3)`   |\n\n        - `\"gaussian_static_spawn\"` : Positions for new chains are sampled from a static Gaussian distribution.\n            Keyword arguments:\n\n            | Name      | Type         | Description                                                | Default            |\n            |-----------|--------------|------------------------------------------------------------|--------------------|\n            | `cov_spawn` | `np.ndarray` | Covariance matrix for the proposal distribution when spawning new chains. | `np.eye(n_dim)`    |\n            | `mean`    | `np.ndarray` | Mean of the proposal distribution when spawning new chains.| `np.zeros(n_dim)`  |\n\n        - `\"proximity_spawn\"` : Positions for new chains are close to existing chains, chains are more likely to be killed when close to others.\n            Keyword arguments:\n\n            | Name          | Type         | Description                                                | Default         |\n            |---------------|--------------|------------------------------------------------------------|-----------------|\n            | `cov_proximity`| `np.ndarray` | Covariance matrix for the proposal distribution when spawning new chains. | `np.eye(n_dim)`  |\n\n\n    Alternatively, keyword arguments allow to pass other arguments to the function, possibly overwriting those set by the mode.\n\n    Args:\n        log_probability (function): The logarithm of the probability function to be used. Also known as the chi^2 potential.\n        **kwargs: Additional keyword arguments that can be passed to the function.\n\n    optional keyword arguments:\n\n    | Name                          | Type         | Description                                                                  | Default                  |\n    |-------------------------------|--------------|------------------------------------------------------------------------------|--------------------------|\n    | `mode`                        | `str`        | See above.                                                                   | `\"proximity_spawn\"`      |\n    | `mu`                          | `float`      | Chemical potential.                                                          | `3`                      |\n    | `n_dim`                       | `int`        | Number of dimensions.                                                        | `2`                      |\n    | `n_initial_particles`         | `int`        | Number of chains to start with.                                              | `100`                    |\n    | `n_total_steps`               | `int`        | Number of total steps to take.                                               | `10000`                  |\n    | `n_thinning`                  | `int`        | Number of steps to skip before storing a sample.                             | `10`                     |\n    | `n_burn_in_steps`             | `int`        | Number of steps to skip before starting to store samples.                    | `n_total_steps/3`        |\n    | `n_pos_updates_per_kill_spawn`| `int`        | Number of position updates to perform before trying to spawn or kill a chain.| `5`                      |\n    | `cov_move`                    | `np.ndarray` | Covariance matrix for the proposal distribution when moving particles.       | `np.eye(n_dim)`          |\n\n\n    Returns:\n        result (Result): The result of the Avalanche Sampling run.\n    \"\"\"\n    # ###\n    # DEFAULTS\n    # ###\n\n    mode = kwargs.pop(\"mode\", \"proximity_spawn\")\n\n    n_dim = kwargs.pop(\"n_dim\", 2)\n    n_initial_particles = kwargs.pop(\"n_initial_particles\", 30)\n    n_total_steps = kwargs.pop(\"n_total_steps\", 100000)\n    n_skip_steps = kwargs.pop(\"n_thinning\", 10)\n    n_burn_in_steps = kwargs.pop(\"n_burn_in_steps\", int(n_total_steps / 10))\n    n_pos_updates_per_kill_spawn = kwargs.pop(\"n_pos_updates_per_kill_spawn\", 3)\n    cov_move = kwargs.pop(\"cov_move\", np.eye(n_dim) / n_dim)\n    progress_bar = kwargs.pop(\"progress_bar\", True)\n\n    log_evidence = kwargs.pop(\"log_evidence\", None)\n    n_particles_wanted = kwargs.pop(\"n_particles\", None)\n    # TODO: should we keep the following?\n    if log_evidence:\n        if not n_particles_wanted:\n            mu = kwargs.pop(\"mu\", np.log(n_initial_particles) - log_evidence)\n        else:\n            mu = kwargs.pop(\"mu\", np.log(n_particles_wanted) - log_evidence)\n    else:\n        mu = kwargs.pop(\"mu\", 3)\n        if n_particles_wanted:\n            raise ValueError(\n                \"Error: no evidence provided, cannot compute chemical potential to reach desired number of particles\"\n            )\n    standard_move = CanonicalMove(log_probability, cov_move)\n    # mode specific arguments\n    spawn_range = kwargs.pop(\"spawn_range\", (-1, 1))\n    initial_positions = kwargs.pop(\n        \"initial_positions\", np.random.uniform(spawn_range[0], spawn_range[1], (n_initial_particles, n_dim))\n    )\n\n    macro_sampler_hyperparameters = {\n        \"n_total_steps\": n_total_steps,\n        \"progress_bar\": progress_bar,\n        \"initial_positions\": initial_positions,\n    }\n\n    # ###\n    # MODES\n    # ###\n\n    static_spawn_kill = StaticSpawnKill(log_probability, mu, spawn_range, n_dim)\n    mode_updater = {\"static_spawn\": Select(standard_move, static_spawn_kill, n_pos_updates_per_kill_spawn)}\n\n    mean = kwargs.pop(\"mean\", np.zeros(n_dim))\n    cov_spawn = kwargs.pop(\"cov_spawn\", np.eye(n_dim) / n_dim**2)\n    gaussian_static_spawn_kill = GaussianStaticSpawnKill(log_probability, mu, cov_spawn, mean, n_dim)\n    mode_updater[\"gaussian_static_spawn\"] = Select(\n        standard_move, gaussian_static_spawn_kill, n_pos_updates_per_kill_spawn\n    )\n\n    cov_proximity = kwargs.pop(\"cov_proximity\", np.eye(n_dim))\n    proximity_spawn_kill = ProximitySpawnKill(log_probability, mu, cov_proximity)\n    mode_updater[\"proximity_spawn\"] = Select(standard_move, proximity_spawn_kill, n_pos_updates_per_kill_spawn)\n\n    # ###\n    # COLLECTORS\n    # ###\n\n    samples_collector = Samples(n_total_steps, n_burn_in_steps, n_skip_steps, n_initial_particles, n_dim)\n    Hamiltonian(n_total_steps, n_burn_in_steps, n_skip_steps, log_probability)\n    chainsize_collector = ChainSize(n_total_steps, n_burn_in_steps, n_skip_steps)\n    AvgSecondMoment(n_total_steps, n_burn_in_steps, n_skip_steps, n_dim)\n    collectors = kwargs.pop(\"collectors\", [chainsize_collector, samples_collector])\n\n    # ###\n    # RUN\n    # ###\n\n    # check if keyword arguments are valid\n    if kwargs:\n        raise TypeError(\"The following keyword arguments are unknown: \", kwargs.keys())\n\n    if mode not in mode_updater:\n        raise ValueError(\"Mode '\" + str(mode) + \"' not recognised\")\n\n    result = macro_sampler(mode_updater[mode], collectors=collectors, **macro_sampler_hyperparameters)\n\n    return Result({**result, **macro_sampler_hyperparameters, **kwargs, \"n_dim\": n_dim, \"mu\": mu, \"mode\": mode})\n</code></pre>"},{"location":"modules/#updaters","title":"Updaters","text":""},{"location":"modules/#mcmcupdater","title":"<code>MCMCUpdater</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for updating the state of a sampler.</p> Source code in <code>avalanchepy/updaters.py</code> <pre><code>class MCMCUpdater(ABC):\n    \"\"\"Abstract class for updating the state of a sampler.\"\"\"\n\n    @abstractmethod\n    def update(self, state: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        \"\"\"Update the sampler state.\n\n        Args:\n            state (np.ndarray): Current state of the sampler.\n\n        Returns:\n            np.ndarray: New state of the sampler.\n            str:        what action was taken (move, spawn, kill, etc)\n            bool:       whether the state change was accepted\n        \"\"\"\n        pass\n\n    def __call__(self, state: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        return self.update(state)\n</code></pre>"},{"location":"modules/#avalanchepy.updaters.MCMCUpdater.update","title":"<code>update(state)</code>  <code>abstractmethod</code>","text":"<p>Update the sampler state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ndarray</code> <p>Current state of the sampler.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <p>np.ndarray: New state of the sampler.</p> <code>str</code> <code>int</code> <p>what action was taken (move, spawn, kill, etc)</p> <code>bool</code> <code>str</code> <p>whether the state change was accepted</p> Source code in <code>avalanchepy/updaters.py</code> <pre><code>@abstractmethod\ndef update(self, state: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n    \"\"\"Update the sampler state.\n\n    Args:\n        state (np.ndarray): Current state of the sampler.\n\n    Returns:\n        np.ndarray: New state of the sampler.\n        str:        what action was taken (move, spawn, kill, etc)\n        bool:       whether the state change was accepted\n    \"\"\"\n    pass\n</code></pre>"},{"location":"modules/#select","title":"<code>Select</code>","text":"<p>             Bases: <code>MCMCUpdater</code></p> <p>MCMCUpdater for the standard case: mostly canonical moves of individual chains are performed, every few iterations, there is a spawn/kill step.</p> <p>Parameters:</p> Name Type Description Default <code>move</code> <code>MCMCUpdater</code> <p>for the move steps</p> required <code>spawn_kill</code> <code>MCMCUpdater</code> <p>for the spawn/kill steps</p> required <code>n_pos_updates_per_kill_spawn</code> <code>int</code> <p>number of move steps between any spawn/kill step</p> required Source code in <code>avalanchepy/updaters.py</code> <pre><code>class Select(MCMCUpdater):\n    \"\"\"MCMCUpdater for the standard case: mostly canonical moves of\n    individual chains are performed, every few iterations, there is a\n    spawn/kill step.\n\n    Args:\n        move (MCMCUpdater):         for the move steps\n        spawn_kill (MCMCUpdater):   for the spawn/kill steps\n        n_pos_updates_per_kill_spawn (int): number of move steps between any spawn/kill step\n    \"\"\"\n\n    def __init__(self, move: MCMCUpdater, spawn_kill: MCMCUpdater, n_pos_updates_per_kill_spawn: int):\n        self.move = move\n        self.spawn_kill = spawn_kill\n        self.counter = 0\n        self.n_pos_updates_per_kill_spawn = n_pos_updates_per_kill_spawn\n\n    def update(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        self.counter += 1\n        if self.counter % self.n_pos_updates_per_kill_spawn == 0:  # kill or spawn\n            return self.spawn_kill(pos)\n        else:  # move\n            return self.move(pos)\n</code></pre>"},{"location":"modules/#canonicalmove","title":"<code>CanonicalMove</code>","text":"<p>             Bases: <code>MCMCUpdater</code></p> <p>performs a move of a random chain according to the Metropolis-Hastings algorithm for the canonical partition sum.</p> <p>Parameters:</p> Name Type Description Default <code>log_probability</code> <code>Callable</code> <p>log_probability potential from the likelihood</p> required <code>cov_move</code> <code>ndarray</code> <p>covariance matrix of the normal distribution used to propose         the new position of the thain</p> required Source code in <code>avalanchepy/updaters.py</code> <pre><code>class CanonicalMove(MCMCUpdater):\n    \"\"\"performs a move of a random chain according to the Metropolis-Hastings\n    algorithm for the canonical partition sum.\n\n    Args:\n        log_probability:       log_probability potential from the likelihood\n        cov_move:   covariance matrix of the normal distribution used to propose\n                    the new position of the thain\n    \"\"\"\n\n    def __init__(self, log_probability: Callable, cov_move: np.ndarray):\n        self.log_probability = log_probability\n        self.cov_move = cov_move\n\n    def update(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        index = int(np.random.randint(0, pos.shape[0]))\n        theta_new = np.random.multivariate_normal(pos[index], self.cov_move)\n\n        delta = -self.log_probability(theta_new) + self.log_probability(pos[index])\n        if np.random.rand() &lt; np.exp(-delta):\n            pos[index] = theta_new\n            return pos, index, \"move\", True\n        else:\n            return pos, index, \"move\", False\n</code></pre>"},{"location":"modules/#staticspawnkill","title":"<code>StaticSpawnKill</code>","text":"<p>             Bases: <code>MCMCUpdater</code></p> <p>spawn positions for new chains are sampled from a uniform distribution covering a given area, the chains to kill are selected at random.</p> <p>Parameters:</p> Name Type Description Default <code>log_probability</code> <code>Callable</code> <p>log_probability potential from the likelihood</p> required <code>mu</code> <code>float</code> <p>chemical potential</p> required <code>spawn_range</code> <code>Tuple[float, float]</code> <p>characterises area where chains may spawn (same             boundaries over all dimensions)</p> required <code>n_dim</code> <code>int</code> <p>dimension of the parameter space</p> required Source code in <code>avalanchepy/updaters.py</code> <pre><code>class StaticSpawnKill(MCMCUpdater):\n    \"\"\"spawn positions for new chains are sampled from a uniform distribution\n    covering a given area, the chains to kill are selected at random.\n\n    Args:\n        log_probability:log_probability potential from the likelihood\n        mu:             chemical potential\n        spawn_range:    characterises area where chains may spawn (same\n                        boundaries over all dimensions)\n        n_dim:          dimension of the parameter space\n    \"\"\"\n\n    def __init__(self, log_probability: Callable, mu: float, spawn_range: Tuple[float, float], n_dim: int):\n        self.log_probability = log_probability\n        self.mu = mu\n        self.spawn_range = spawn_range\n        self.n_dim = n_dim\n\n    def update(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        if np.random.rand() &lt; 0.5:\n            return self.spawn(pos)\n        else:\n            return self.kill(pos)\n\n    def spawn(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        theta_new = np.random.uniform(self.spawn_range[0], self.spawn_range[1], self.n_dim)\n        delta = self.mu + self.log_probability(theta_new)\n        acceptance_probability = (\n            np.exp(delta) / (pos.shape[0] + 1) * (self.spawn_range[1] - self.spawn_range[0]) ** self.n_dim\n        )\n\n        if np.random.rand() &lt; acceptance_probability:\n            pos = np.vstack([pos, theta_new])\n            return pos, -1, \"spawn\", True\n        else:\n            return pos, -1, \"spawn\", False\n\n    def kill(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        kill_idx = int(np.random.randint(0, pos.shape[0]))\n        delta = -self.mu - self.log_probability(pos[kill_idx])\n        acceptance_probability = (\n            np.exp(delta)\n            * pos.shape[0]\n            / (self.spawn_range[1] - self.spawn_range[0]) ** self.n_dim\n            / np.float64(np.all((pos[kill_idx] &gt; self.spawn_range[0]) &amp; (pos[kill_idx] &lt; self.spawn_range[1])))\n        )\n\n        if np.random.rand() &lt; acceptance_probability:\n            pos = np.delete(pos, kill_idx, axis=0)\n            return pos, kill_idx, \"kill\", True\n        else:\n            return pos, kill_idx, \"kill\", False\n</code></pre>"},{"location":"modules/#gaussianstaticspawnkill","title":"<code>GaussianStaticSpawnKill</code>","text":"<p>             Bases: <code>MCMCUpdater</code></p> <p>spawn positions for new chains are dsamplern from a gaussian distribution with given covariance around the origin, the chains to kill are selected at random.</p> <p>Parameters:</p> Name Type Description Default <code>log_probability</code> <code>Callable</code> <p>log_probability potential from the likelihood</p> required <code>mu</code> <code>float</code> <p>chemical potential</p> required <code>spawn_cov</code> <p>characterises gaussians where chains may spawn</p> required <code>n_dim</code> <code>int</code> <p>dimension of the parameter space</p> required Source code in <code>avalanchepy/updaters.py</code> <pre><code>class GaussianStaticSpawnKill(MCMCUpdater):\n    \"\"\"spawn positions for new chains are dsamplern from a gaussian distribution\n    with given covariance around the origin, the chains to kill are selected at random.\n\n    Args:\n        log_probability: log_probability potential from the likelihood\n        mu:              chemical potential\n        spawn_cov:       characterises gaussians where chains may spawn\n        n_dim:           dimension of the parameter space\n    \"\"\"\n\n    def __init__(self, log_probability: Callable, mu: float, cov_spawn: np.ndarray, mean: np.ndarray, n_dim: int):\n        self.log_probability = log_probability\n        self.mu = mu\n        self.cov_spawn = cov_spawn\n        self.n_dim = n_dim\n        self.mean = mean\n\n        self.cov_spawn_inv = np.linalg.inv(cov_spawn)\n        self.norm_factor = 1 / np.sqrt(np.linalg.det(2 * np.pi * self.cov_spawn))\n        if cov_spawn.shape != (n_dim, n_dim):\n            raise ValueError(\"spawn_cov must be a square matrix of dimension n_dim\")\n        if mean.shape != (n_dim,):\n            raise ValueError(\"mean must be a vector of dimension n_dim\")\n\n    def update(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        if np.random.rand() &lt; 0.5:\n            return self.spawn(pos)\n        else:\n            return self.kill(pos)\n\n    def spawn(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        theta_new = np.random.multivariate_normal(self.mean, self.cov_spawn)\n\n        delta = self.mu + self.log_probability(theta_new)\n        acceptance_probability = (\n            np.exp(delta)\n            / (pos.shape[0] + 1)\n            / self.norm_factor\n            / np.exp(-0.5 * np.dot(theta_new - self.mean, np.dot(self.cov_spawn_inv, theta_new - self.mean)))\n        )\n\n        if np.random.rand() &lt; acceptance_probability:\n            pos = np.vstack([pos, theta_new])\n            return pos, -1, \"spawn\", True\n        else:\n            return pos, -1, \"spawn\", False\n\n    def kill(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        kill_idx = int(np.random.randint(0, pos.shape[0]))\n        delta = -self.mu - self.log_probability(pos[kill_idx])\n        acceptance_probability = (\n            np.exp(delta)\n            * pos.shape[0]\n            * self.norm_factor\n            * np.exp(-0.5 * np.dot(pos[kill_idx] - self.mean, np.dot(self.cov_spawn_inv, pos[kill_idx] - self.mean)))\n        )\n\n        if np.random.rand() &lt; acceptance_probability:\n            pos = np.delete(pos, kill_idx, axis=0)\n            return pos, kill_idx, \"kill\", True\n        else:\n            return pos, kill_idx, \"kill\", False\n</code></pre>"},{"location":"modules/#proximityspawnkill","title":"<code>ProximitySpawnKill</code>","text":"<p>             Bases: <code>MCMCUpdater</code></p> <p>spawn positions for new chains are sampled from a gaussian distribution with given covariance around the origin, the chains to kill are selected based on the proximity of the chains.</p> <p>Parameters:</p> Name Type Description Default <code>log_probability</code> <code>Callable</code> <p>log_probability potential from the likelihood</p> required <code>mu</code> <code>float</code> <p>chemical potential</p> required <code>cov_proximity</code> <code>ndarray</code> <p>characterises gaussians where chains may spawn</p> required Source code in <code>avalanchepy/updaters.py</code> <pre><code>class ProximitySpawnKill(MCMCUpdater):\n    \"\"\"spawn positions for new chains are sampled from a gaussian distribution\n    with given covariance around the origin, the chains to kill are selected\n    based on the proximity of the chains.\n\n    Args:\n        log_probability: log_probability potential from the likelihood\n        mu:              chemical potential\n        cov_proximity:   characterises gaussians where chains may spawn\n    \"\"\"\n\n    def __init__(self, log_probability: Callable, mu: float, cov_proximity: np.ndarray):\n        self.log_probability = log_probability\n        self.mu = mu\n        self.cov_proximity = cov_proximity\n        self.cov_proximity_inv = np.linalg.inv(cov_proximity)\n        self.det_cov_proximity = np.linalg.det(cov_proximity)\n        self.n_dim = cov_proximity.shape[0]\n\n    def update(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        if np.random.rand() &lt; 0.5:\n            return self.spawn(pos)\n        else:\n            return self.kill(pos)\n\n    def calc_P_C(self, pos: np.ndarray) -&gt; np.ndarray:\n        distances = pos[None, :, :] - pos[:, None, :]\n        P_C = (\n            1\n            / np.sqrt((2 * np.pi) ** self.n_dim * self.det_cov_proximity)\n            * np.exp(-1 / 2 * np.einsum(\"ij,kli,klj-&gt;kl\", self.cov_proximity_inv, distances, distances, optimize=True))\n        )\n        return np.array(P_C)\n\n    def kill(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        P_C = self.calc_P_C(pos)\n        p = np.sum(P_C, axis=1) - np.diagonal(P_C)\n        p /= np.sum(p)\n        kill_idx = int(np.random.choice(range(pos.shape[0]), p=p))\n        if np.random.rand() &lt; np.exp(-self.mu - self.log_probability(pos[kill_idx])) * (np.sum(P_C) - np.trace(P_C)) / (\n            pos.shape[0] - 1\n        ):\n            return np.delete(pos, kill_idx, axis=0), kill_idx, \"kill\", True\n        else:\n            return pos, kill_idx, \"kill\", False\n\n    def spawn(self, pos: np.ndarray) -&gt; Tuple[np.ndarray, int, str, bool]:\n        theta_new = np.random.multivariate_normal(pos[np.random.randint(pos.shape[0])], self.cov_proximity)\n        P_C = self.calc_P_C(np.vstack([pos, theta_new]))\n        if np.random.rand() &lt; np.exp(self.mu + self.log_probability(theta_new)) * pos.shape[0] / (\n            np.sum(P_C) - np.trace(P_C)\n        ):\n            return np.vstack([pos, theta_new]), -1, \"spawn\", True\n        else:\n            return pos, -1, \"spawn\", False\n</code></pre>"},{"location":"modules/#collectors","title":"Collectors","text":""},{"location":"modules/#avalanchepy.collectors.AvgSecondMoment","title":"<code>AvgSecondMoment</code>","text":"<p>             Bases: <code>Collector</code></p> <p>measures the second moment averaged over all chains</p> Source code in <code>avalanchepy/collectors.py</code> <pre><code>class AvgSecondMoment(Collector):\n    \"\"\"measures the second moment averaged over all chains\"\"\"\n\n    def __init__(self, expected_length: int, burn_in: int, thinning: int, n_dims: int) -&gt; None:\n        super().__init__(\"avg_second_moment\", expected_length, burn_in, thinning)\n\n        self.n_dims = n_dims\n        self.values = np.zeros((expected_length, n_dims, n_dims), dtype=np.float64)\n\n    def collect(self, pos: np.ndarray, i: int, touched_chain: int, action: str, success: bool) -&gt; None:\n        self.values[i] = 1 / pos.shape[0] * np.einsum(\"li,lj-&gt;ij\", pos, pos)\n</code></pre>"},{"location":"modules/#avalanchepy.collectors.ChainSize","title":"<code>ChainSize</code>","text":"<p>             Bases: <code>Collector</code></p> <p>measures the number of chains</p> Source code in <code>avalanchepy/collectors.py</code> <pre><code>class ChainSize(Collector):\n    \"\"\"measures the number of chains\"\"\"\n\n    def __init__(self, expected_length: int, burn_in: int, thinning: int):\n        super().__init__(\"n_chains\", expected_length, burn_in, thinning)\n\n        self.values = np.zeros(expected_length, dtype=int)\n        self.abbreviation = \"N\"\n\n    def collect(self, state: np.ndarray, i: int, touched_chain: int, action: str, success: bool) -&gt; None:\n        self.values[i] = state.shape[0]\n        return None\n</code></pre>"},{"location":"modules/#avalanchepy.collectors.Collector","title":"<code>Collector</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for collecting data from the MCMC simulation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the collector/observable</p> required <code>expected_length</code> <code>int</code> <p>expected length of the measured data</p> required <code>burn_in</code> <code>int</code> <p>number of steps to be discarded at the beginning of run</p> <code>0</code> <code>thinning</code> <code>int</code> <p>number of steps to skip between each measurement</p> <code>1</code> Source code in <code>avalanchepy/collectors.py</code> <pre><code>class Collector(ABC):\n    \"\"\"Abstract class for collecting data from the MCMC simulation.\n\n    Args:\n        name (str): name of the collector/observable\n        expected_length (int): expected length of the measured data\n        burn_in (int): number of steps to be discarded at the beginning of run\n        thinning (int): number of steps to skip between each measurement\n    \"\"\"\n\n    def __init__(self, name: str, expected_length: int, burn_in: int = 0, thinning: int = 1):\n        self.name = name\n        self.burn_in = burn_in\n        self.thinning = thinning\n\n        self.values = np.zeros(expected_length)\n        self.abbreviation = name\n\n    @abstractmethod\n    def collect(self, state: np.ndarray, i: int, touched_chain: int, action: str, success: bool) -&gt; None:\n        return None\n\n    def get(self, i: int) -&gt; np.ndarray:\n        return self.values[:i]\n\n    def get_clean(self, i: int) -&gt; np.ndarray:\n        return self.values[self.burn_in :: self.thinning]\n\n    def get_recent_average(self, i: int, window_size: int = 100) -&gt; np.float64:\n        return np.mean(self.values[i - window_size : i])\n</code></pre>"},{"location":"modules/#avalanchepy.collectors.Hamiltonian","title":"<code>Hamiltonian</code>","text":"<p>             Bases: <code>Collector</code></p> <p>measures the energy of the system, i.e. the Hamiltonian</p> Source code in <code>avalanchepy/collectors.py</code> <pre><code>class Hamiltonian(Collector):\n    \"\"\"measures the energy of the system, i.e. the Hamiltonian\"\"\"\n\n    def __init__(\n        self,\n        expected_length: int,\n        burn_in: int,\n        thinning: int,\n        log_probability: Callable[[np.ndarray], np.ndarray[float]],\n    ):\n        super().__init__(\"hamiltonian\", expected_length, burn_in, thinning)\n        self.hamiltonian = lambda state: np.sum(log_probability(state))\n        self.abbreviation = \"H\"\n\n    def collect(self, state: np.ndarray, i: int, touched_chain: int, action: str, success: bool) -&gt; None:\n        self.values[i] = self.hamiltonian(state)\n        return None\n</code></pre>"},{"location":"modules/#avalanchepy.collectors.Samples","title":"<code>Samples</code>","text":"<p>             Bases: <code>Collector</code></p> <p>collects the samples every few steps after burn-in, not ordered by chains</p> Source code in <code>avalanchepy/collectors.py</code> <pre><code>class Samples(Collector):\n    \"\"\"collects the samples every few steps after burn-in, not ordered\n    by chains\"\"\"\n\n    def __init__(self, expected_length: int, burn_in: int, thinning: int, expected_n_chains: int, n_dims: int):\n        super().__init__(\"samples\", expected_length, burn_in, thinning)\n        # self.values = np.zeros((expected_n_chains * (expected_length-burn_in) // thinning, n_dims))\n        # self.values = np.zeros((expected_length*expected_n_chains, n_dims))\n        self.values = np.zeros((expected_length, n_dims))\n        self.last_idx = 0\n\n    def collect(self, state: np.ndarray, i: int, touched_chain: int, action: str, success: bool) -&gt; None:\n        # print(self.values.shape, state.shape, i)\n        if action == \"kill\" and success:\n            self.values[self.last_idx] = state[np.random.randint(state.shape[0])]\n        else:\n            self.values[self.last_idx] = state[touched_chain]\n        self.last_idx += 1\n\n    def get(self, i: int) -&gt; np.ndarray:\n        return self.values[: self.last_idx]\n\n    def get_clean(self, i: int) -&gt; np.ndarray:\n        return self.get(i)[self.burn_in :: self.thinning]\n</code></pre>"}]}